{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77dbf66",
   "metadata": {},
   "source": [
    "# An√°lisis de Ventas con PySpark\n",
    "Este notebook realiza un an√°lisis de datos de ventas usando Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69589121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar configuraciones\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "os.makedirs(\"resultados\", exist_ok=True)\n",
    "\n",
    "from config.spark_config import SparkSession\n",
    "from etl.transformaciones import TransformacionesVentas\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.getActiveSession()\n",
    "if spark:\n",
    "    spark.stop()\n",
    "\n",
    "# Inicializar Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AnalisisVentas-Notebook\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "transformaciones = TransformacionesVentas(spark)\n",
    "spark.conf.get(\"spark.sql.catalogImplementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca79ebb",
   "metadata": {},
   "source": [
    "# Cargar datos\n",
    "Se importan los DataFrames de ventas y productos para iniciar el an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bee219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "ventas_df, productos_df = transformaciones.cargar_datos()\n",
    "\n",
    "print(\"üìä Vista previa de ventas:\")\n",
    "ventas_df.show(5)\n",
    "\n",
    "print(\"\\nüì¶ Vista previa de productos:\")\n",
    "productos_df.show(5)\n",
    "\n",
    "print(f\"\\nTotal ventas: {ventas_df.count()}\")\n",
    "print(f\"Total productos: {productos_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca17b8",
   "metadata": {},
   "source": [
    "# Esquema de datos\n",
    "Verificaci√≥n de los tipos de datos de cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Esquema ventas:\")\n",
    "ventas_df.printSchema()\n",
    "\n",
    "print(\"\\nEsquema productos:\")\n",
    "productos_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90757a88",
   "metadata": {},
   "source": [
    "# Calcular m√©tricas y An√°lisis Temporal\n",
    "C√°lculo de ingresos por categor√≠a, an√°lisis de ventas por fecha y identificaci√≥n de mejores clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24355062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular m√©tricas\n",
    "ventas_completas_df, metricas_df = transformaciones.calcular_metricas(ventas_df, productos_df)\n",
    "\n",
    "print(\"üìà M√©tricas por categor√≠a:\")\n",
    "metricas_df.show()\n",
    "\n",
    "# An√°lisis temporal\n",
    "analisis_temporal_df = transformaciones.analisis_temporal(ventas_df)\n",
    "\n",
    "print(\"üìÖ An√°lisis por fecha:\")\n",
    "analisis_temporal_df.show()\n",
    "\n",
    "# Top clientes\n",
    "top_clientes_df = transformaciones.top_clientes(ventas_df, top_n=5)\n",
    "\n",
    "print(\"üëë Top 5 clientes:\")\n",
    "top_clientes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis adicional: Ventas por producto\n",
    "ventas_por_producto = ventas_completas_df.groupBy(\"nombre\", \"categoria\") \\\n",
    "    .agg(\n",
    "        F.sum(\"cantidad\").alias(\"unidades_vendidas\"),\n",
    "        F.sum(\"venta_total\").alias(\"ingresos\"),\n",
    "        F.round(F.avg(\"precio_unitario\"), 2).alias(\"precio_promedio\")\n",
    "    ) \\\n",
    "    .orderBy(F.desc(\"ingresos\"))\n",
    "\n",
    "print(\"üèÜ Productos m√°s vendidos:\")\n",
    "ventas_por_producto.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63008e",
   "metadata": {},
   "source": [
    "# Visualizaci√≥n\n",
    "Representaci√≥n gr√°fica de los ingresos por categor√≠a usando Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Convertir a pandas para visualizaci√≥n\n",
    "    metricas_pandas = metricas_df.toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(metricas_pandas['categoria'], metricas_pandas['ingresos_totales'])\n",
    "    plt.title('Ingresos por Categor√≠a')\n",
    "    plt.xlabel('Categor√≠a')\n",
    "    plt.ylabel('Ingresos Totales')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Matplotlib no disponible para visualizaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820437ff",
   "metadata": {},
   "source": [
    "# Guardar resultados\n",
    "Exportaci√≥n de los datos procesados a formato Parquet (optimizada para Big Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4188d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"üíæ Guardando resultados...\")\n",
    "\n",
    "# Obtener ruta base del proyecto din√°micamente\n",
    "project_root = os.getcwd()\n",
    "output_dir = os.path.join(project_root, \"resultados\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Convertir a formato que Spark entiende\n",
    "output_uri = f\"file://{output_dir}\"\n",
    "\n",
    "# Guardar\n",
    "metricas_df.write.mode(\"overwrite\").parquet(f\"{output_uri}/metricas_ventas.parquet\")\n",
    "ventas_completas_df.write.mode(\"overwrite\").parquet(f\"{output_uri}/ventas_completas.parquet\")\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en formato Parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097d200",
   "metadata": {},
   "source": [
    "# Consultas SQL con Hive\n",
    "Uso de Spark SQL para realizar consultas sobre tablas temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38603371",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Crear tabla Hive temporal\n",
    "    ventas_completas_df.createOrReplaceTempView(\"ventas_completas\")\n",
    "    \n",
    "    print(\"üîç Consulta SQL a trav√©s de Hive:\")\n",
    "    resultado_sql = spark.sql(\"\"\"\n",
    "        SELECT categoria, \n",
    "               SUM(venta_total) as ingresos_totales,\n",
    "               AVG(precio_unitario) as precio_promedio\n",
    "        FROM ventas_completas\n",
    "        GROUP BY categoria\n",
    "        ORDER BY ingresos_totales DESC\n",
    "    \"\"\")\n",
    "    resultado_sql.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Hive no disponible: {e}\")\n",
    "\n",
    "# Detener Spark\n",
    "from config.spark_config import detener_spark_session\n",
    "detener_spark_session(spark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
